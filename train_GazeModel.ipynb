{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T14:44:24.669695Z","iopub.status.busy":"2024-05-15T14:44:24.669318Z","iopub.status.idle":"2024-05-15T14:44:28.547383Z","shell.execute_reply":"2024-05-15T14:44:28.546378Z","shell.execute_reply.started":"2024-05-15T14:44:24.669665Z"},"id":"QXO3pKFNyYo0","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","gpus=tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu,True)\n","print(gpus)\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from PIL import Image\n","import os,glob, random\n","tf.__version__"]},{"cell_type":"markdown","metadata":{},"source":["<font color='red' size=4><b>Note: Because of lack of resources only frst two person's data is processed.<br>\n","p00,p01 and p03 data will be used for calibration testing"]},{"cell_type":"markdown","metadata":{},"source":["<font color='green' size=6><b> Training Pipeline Design"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T14:44:34.292963Z","iopub.status.busy":"2024-05-15T14:44:34.291818Z","iopub.status.idle":"2024-05-15T14:44:43.493193Z","shell.execute_reply":"2024-05-15T14:44:43.492086Z","shell.execute_reply.started":"2024-05-15T14:44:34.292927Z"},"trusted":true},"outputs":[],"source":["face,lefteye,righteye,rotation_matrix,gaze,subject_id,eye_coords=[],[],[],[],[],[],[]\n","subject_map={}\n","data_path='processed_data/Image'\n","persons=os.listdir(data_path)\n","persons.sort()\n","print(persons)\n","id=0\n","for person in persons[:2]:\n","    face+=glob.glob(f'{data_path}/{person}/face/*')\n","    lefteye+=glob.glob(f'{data_path}/{person}/lefteye/*')\n","    righteye+=glob.glob(f'{data_path}/{person}/righteye/*')\n","    rotation_matrix+=glob.glob(f'{data_path}/{person}/rotation_matrix/*')\n","    gaze+=glob.glob(f'{data_path}/{person}/3d_gaze/*')\n","    subject_id+=[f'{data_path}/{person}' for _ in range(len(face))]\n","    eye_coords+=glob.glob(f'{data_path}/{person}/eye_coords/*')\n","    subject_map[f'{data_path}/{person}']=id\n","    id+=1\n","face.sort()\n","lefteye.sort()\n","righteye.sort()\n","rotation_matrix.sort()\n","gaze.sort()\n","eye_coords.sort()\n","subject_id.sort()\n","print(len(lefteye))\n","data=list(zip(face,lefteye,righteye,rotation_matrix,eye_coords,subject_id,gaze))   \n","random.seed(12)\n","random.shuffle(data)\n","data=tf.data.experimental.from_list(data)\n","print(subject_map)"]},{"cell_type":"markdown","metadata":{},"source":["###  Tensorflow StaticHashtable for ids to passed in to embedding which can be used in tf.data pipeline"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T14:44:48.723969Z","iopub.status.busy":"2024-05-15T14:44:48.723588Z","iopub.status.idle":"2024-05-15T14:44:48.734868Z","shell.execute_reply":"2024-05-15T14:44:48.733903Z","shell.execute_reply.started":"2024-05-15T14:44:48.723940Z"},"trusted":true},"outputs":[],"source":["subject_map=tf.lookup.StaticHashTable( tf.lookup.KeyValueTensorInitializer(list(subject_map.keys()), \n","                                        list(subject_map.values())),default_value=-1)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T14:44:51.084076Z","iopub.status.busy":"2024-05-15T14:44:51.083706Z","iopub.status.idle":"2024-05-15T14:44:51.094171Z","shell.execute_reply":"2024-05-15T14:44:51.093077Z","shell.execute_reply.started":"2024-05-15T14:44:51.084046Z"},"trusted":true},"outputs":[],"source":["@tf.function\n","def load_img(img):\n","    img=tf.io.read_file(img)\n","    img=tf.io.decode_jpeg(img,3)\n","    return img\n","@tf.numpy_function(Tout=tf.float32)\n","def ld(x):\n","    return np.load(x).astype('float32').ravel()\n","@tf.function\n","def map_fn(face,lefteye,righteye,rotation_matrix,eye_coords,subject_id,gaze):\n","    face=load_img(face)\n","    flipped_face=tf.image.flip_left_right(face)\n","    lefteye=load_img(lefteye)\n","    righteye=load_img(righteye)\n","    rotation_matrix=ld(rotation_matrix)\n","    eye_coords=ld(eye_coords)\n","    id=subject_map[subject_id]\n","    gaze=ld(gaze)\n","    return {\n","            'face':face,\n","            'flipped_face':flipped_face,\n","            'lefteye':lefteye,\n","            'righteye':righteye,\n","            'rotation_matrix':rotation_matrix,\n","            'eye_coords':eye_coords,\n","            'id':id},gaze\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["next(iter(data.map(map_fn).batch(5)))"]},{"cell_type":"markdown","metadata":{},"source":["### Pretrained CNN models for the CNNs to extract feature from face and eye images EfficientNetV2 and VGG16"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["tf.keras.backend.clear_session()\n","effcnt_net=tf.keras.applications.EfficientNetV2B0(include_top=False,\n","                                            include_preprocessing=True,\n","                                            pooling=None)\n","\n","effcnt_net.trainable=True\n","vgg16=tf.keras.applications.VGG16(include_top=False,pooling=None)\n","vgg16.trainable=True\n","vgg16_processor=tf.keras.applications.vgg16.preprocess_input"]},{"cell_type":"markdown","metadata":{},"source":["### g_face and g_eye"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["g_face=tf.keras.Model(inputs=effcnt_net.inputs,outputs=effcnt_net.outputs,name='g_face')\n","g_eye=tf.keras.Model(inputs=vgg16.inputs,outputs=vgg16.outputs,name='g_eye')"]},{"cell_type":"markdown","metadata":{},"source":["### GazeModel implementation"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class GazeModel(tf.keras.Model):\n","    def __init__(self):\n","        super(GazeModel,self).__init__()\n","        self.g_face=g_face\n","        self.g_eye=g_eye\n","        self.flat=tf.keras.layers.Flatten()\n","        # Embedding layer as described in the paper\n","        self.embedding=tf.keras.layers.Embedding(3,6,\n","                                                 embeddings_regularizer=tf.keras.regularizers.L2(l2=0.01),\n","                                                 mask_zero=True,name='subject_embedding')\n","        #gradients wont pass through embedding layer upto 40 epochs\n","        self.embedding.trainable=False\n","        #MLP where concatenated features will be passed\n","        self.MLP=tf.keras.Sequential([\n","            tf.keras.layers.Dense(1280,activation='relu'),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.Dense(3,name='gaze_location'),\n","            ],name='MLP')\n","\n","    def call(self,input_dict):\n","        #face features from g_face\n","        face_features=self.g_face(input_dict['face'])\n","        #flipped face features from g_face \n","        flipped_face_features=self.g_face(input_dict['flipped_face'])\n","        #left eye features from g_eye\n","        left_features=vgg16_processor(input_dict['lefteye'])\n","        left_features=self.g_eye(left_features)\n","        #right eye features from g_eye\n","        right_features=vgg16_processor(input_dict['righteye'])\n","        right_features=self.g_eye(right_features)\n","        #flattening of feature matrices\n","        face_features=self.flat(face_features)\n","        flipped_face_features=self.flat(flipped_face_features)\n","        left_features=self.flat(left_features)\n","        right_features=self.flat(right_features)\n","        # subject embedding or person specific embeddings\n","        embedding=self.embedding(input_dict['id'])\n","        # rotation  matrix\n","        rot_mat=input_dict['rotation_matrix']\n","        # 3d eye coordinates\n","        eye_coords=input_dict['eye_coords']\n","        #concantenation of all the features\n","        total=tf.concat([face_features,flipped_face_features,left_features,\n","                            right_features,eye_coords,embedding,rot_mat],1)\n","        #concantenated features passed to MLP\n","        total=self.MLP(total)\n","        # return face_features, left_features\n","        return total\n"]},{"cell_type":"markdown","metadata":{},"source":["### loss function for GazeModel as described in paper"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["loss_fn=tf.keras.losses.Huber(delta=1.5)"]},{"cell_type":"markdown","metadata":{},"source":["### Optimizer configuration upto 40 epoch"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003,\n","                                   beta_1=0.9,\n","                                   beta_2=0.999,\n","                                   epsilon=1e-7)"]},{"cell_type":"markdown","metadata":{},"source":["### Optimizer configuration post 40 epoch"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["optimizer_post_40_epoch=tf.keras.optimizers.Adam(\n","    learning_rate=tf.keras.optimizers.schedules.CosineDecay(\n","                                        0.0001,\n","                                        10000,\n","                                        alpha=0.0,\n","                                        name='CosineDecay',\n","                                        warmup_target=None,\n","                                        warmup_steps=0\n","                                    ),\n","                                   beta_1=0.9,\n","                                   beta_2=0.999,\n","                                   epsilon=1e-7)\n"]},{"cell_type":"markdown","metadata":{},"source":["### AngularError metric implementation"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class AngularError(tf.keras.metrics.Metric):\n","\n","    def __init__(self, name='mean_angular_error', **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.total_error = self.add_weight(name='total_error', initializer='zeros')\n","        self.num_samples = self.add_weight(name='num_samples', initializer='zeros')\n","        \n","    def update_state(self, y_true, y_pred,sample_weight=None):\n","        y_true = tf.math.l2_normalize(y_true, axis=-1)\n","        y_pred = tf.math.l2_normalize(y_pred, axis=-1)\n","    \n","        dot_product = tf.reduce_sum(y_true * y_pred, axis=-1)\n","        dot_product = tf.clip_by_value(dot_product, -1.0, 1.0)\n","     \n","        angular_error = tf.acos(dot_product)\n","        angular_error=angular_error*57.296\n","        self.total_error.assign_add(tf.reduce_sum(angular_error))\n","        self.num_samples.assign_add(tf.cast(tf.shape(y_true)[0], tf.float32))\n","\n","    def result(self):\n","        return self.total_error / self.num_samples\n","    def reset_state(self):\n","        self.total_error.assign(0.0)\n","        self.num_samples.assign(0.0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-15T15:06:41.893174Z","iopub.status.busy":"2024-05-15T15:06:41.892601Z","iopub.status.idle":"2024-05-15T15:06:51.550024Z","shell.execute_reply":"2024-05-15T15:06:51.549004Z","shell.execute_reply.started":"2024-05-15T15:06:41.893133Z"},"id":"IZbulTm301yq","outputId":"ee230bd4-accf-40eb-b35e-3e3d71f233cb","trusted":true},"outputs":[],"source":["angular_error=AngularError()\n","# post_40_epoch_cb=CallbackAfterEpoch40(angular_error,loss_fn,optimizer_post_40_epoch) \n","model=GazeModel()\n","model.compile(loss=loss_fn,optimizer=optimizer,metrics=[angular_error])\n","print(model(next(iter(data.map(map_fn).batch(1).map(lambda x,y:x)))))\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Train Test split"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:06:30.476023Z","iopub.status.busy":"2024-05-15T15:06:30.475072Z","iopub.status.idle":"2024-05-15T15:06:30.485898Z","shell.execute_reply":"2024-05-15T15:06:30.485008Z","shell.execute_reply.started":"2024-05-15T15:06:30.475989Z"},"trusted":true},"outputs":[],"source":["train_data=data.take(data.cardinality().numpy()*0.8)\n","test_data=data.skip(data.cardinality().numpy()*0.8)"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["best_acc=99999\n","patience=20\n","for epoch in range(200):\n","    print('training....')\n","    model.fit(train_data.map(map_fn,num_parallel_calls=tf.data.AUTOTUNE)\n","          .batch(16,num_parallel_calls=tf.data.AUTOTUNE).prefetch(2),\n","          epochs=1)\n","    print('validation....')\n","    logs=model.evaluate(test_data.map(map_fn).batch(8))\n","    if epoch>40:\n","        patience-=1\n","    if logs[1]<best_acc:\n","        patience=20\n","        best_acc=logs[1]\n","        model.save_weights('best_GazeModel.h5')\n","    if epoch==40:\n","        # embedding layer set to trainable post 40 epoch\n","        embedding_layer=model.get_layer('subject_embedding')\n","        embedding_layer.trainable=True\n","        model.compile(loss=loss_fn,optimizer=optimizer_post_40_epoch,metrics=[angular_error])\n","        model.summary()\n","    if not patience:break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T17:23:34.766739Z","iopub.status.busy":"2024-05-15T17:23:34.765908Z","iopub.status.idle":"2024-05-15T17:23:47.355382Z","shell.execute_reply":"2024-05-15T17:23:47.354410Z","shell.execute_reply.started":"2024-05-15T17:23:34.766705Z"},"trusted":true},"outputs":[],"source":["model.load_weights('best_GazeModel.h5')\n","model.evaluate(test_data.map(map_fn).batch(8))"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5007185,"sourceId":8412769,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
